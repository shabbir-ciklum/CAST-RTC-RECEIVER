<!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>WebRTC Stream Player</title>

        <!-- Cast Framework SDK -->
        <script src="https://www.gstatic.com/cast/sdk/libs/caf_receiver/v3/cast_receiver_framework.js"></script>

        <!-- Firebase SDK -->
        <script src="https://www.gstatic.com/firebasejs/10.7.1/firebase-app-compat.js"></script>
        <script src="https://www.gstatic.com/firebasejs/10.7.1/firebase-analytics-compat.js"></script>
        <script src="https://www.gstatic.com/firebasejs/10.7.1/firebase-firestore-compat.js"></script>

        <script src="https://cdn.jsdelivr.net/npm/@twind/cdn"></script>
        <style>
            html, body {
                  margin: 0;
                  padding: 0;
                  width: 100%;
                  height: 100%;
                  overflow: hidden;
                  position: fixed;
                }

            /* Ensure video container is constrained */
            #remoteVideo {
              position: absolute;
              top: 0;
              left: 0;
              width: 100%;
              height: 100%;
              object-fit: contain;
              max-width: 100vw;
              max-height: 100vh;
            }
    
            .scroller::-webkit-scrollbar { width: 8px; }
            .scroller::-webkit-scrollbar-track { background: #1f2937; }
            .scroller::-webkit-scrollbar-thumb { background: #4b5563; border-radius: 4px; }
            .scroller::-webkit-scrollbar-thumb:hover { background: #6b7280; }
        </style>
    </head>
    <body class="bg-gray-900 text-white min-h-screen flex flex-col font-sans">

        <!-- Header -->
        <header class="bg-gray-800 border-b border-gray-700 p-4 shadow-lg">
            <div class="max-w-6xl mx-auto flex justify-between items-center">
                <h1 class="text-xl font-bold text-blue-400 flex items-center gap-2">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 10l4.553-2.276A1 1 0 0121 8.618v6.764a1 1 0 01-1.447.894L15 14M5 18h8a2 2 0 002-2V8a2 2 0 00-2-2H5a2 2 0 00-2 2v8a2 2 0 002 2z" />
                    </svg>
                    iOS WebRTC Monitor
                </h1>
                <div id="connectionStatus" class="flex items-center gap-2 px-3 py-1 rounded-full bg-red-900/50 text-red-200 text-sm font-medium border border-red-800 transition-colors">
                    <div class="w-2 h-2 rounded-full bg-red-500 animate-pulse"></div>
                    Disconnected
                </div>
            </div>
        </header>

        <!-- Main Content -->
        <main class="flex-grow flex flex-col w-full overflow-hidden" style="padding: 0;">
            <!-- Video Container -->
            <div class="relative w-full flex-grow bg-black group" style="min-height: 0; position: relative;">
                <video id="remoteVideo" autoplay playsinline></video>
                
                <div class="absolute inset-0 flex items-center justify-center bg-black/50 transition-opacity duration-300 pointer-events-none" id="loader">
                    <div class="flex flex-col items-center">
                        <svg class="animate-spin h-10 w-10 text-blue-500 mb-2" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                            <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                            <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                        </svg>
                        <span class="text-sm text-gray-300 font-mono" id="loaderText">Initializing...</span>
                    </div>
                </div>
    
                <div class="absolute inset-0 flex items-center justify-center bg-black transition-opacity duration-300 pointer-events-none opacity-0" id="voiceOnlyIndicator">
                    <div class="flex flex-col items-center">
                      <svg class="h-24 w-24 text-blue-400 mb-4 animate-pulse" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15.536 8.464a5 5 0 010 7.072m2.828-9.9a9 9 0 010 12.728M5.586 15H4a1 1 0 01-1-1v-4a1 1 0 011-1h1.586l4.707-4.707C10.923 3.663 12 4.109 12 5v14c0 .891-1.077 1.337-1.707.707L5.586 15z" />
                      </svg>
                      <span class="text-xl text-gray-300 font-medium">Voice Only</span>
                    </div>
                </div>

                <div class="absolute bottom-0 left-0 right-0 p-4 bg-gradient-to-t from-black/90 to-transparent opacity-0 group-hover:opacity-100 transition-opacity duration-200 flex justify-between items-center">
                    <div class="text-xs text-gray-400 font-mono">
                        Protocol: <span class="text-white">Swift Message Struct (Binary Frame)</span>
                    </div>
                    <button onclick="toggleMute()" id="muteBtn" class="bg-gray-700 hover:bg-gray-600 text-white px-3 py-1 rounded text-sm transition font-medium">
                        Mute
                    </button>
                </div>
            </div>

            <!-- Controls & Logs Grid -->
            <div class="w-full grid grid-cols-1 md:grid-cols-3 gap-4" style="display: none;">
                <!-- Config Panel -->
                <div class="bg-gray-800 rounded-lg p-4 border border-gray-700">
                    <h3 class="text-sm font-semibold text-gray-400 uppercase tracking-wider mb-3">Configuration</h3>
                    <div class="space-y-2 text-sm">
                        <div class="flex justify-between">
                            <span class="text-gray-500">Signaling URL:</span>
                            <span class="text-blue-300 font-mono">\(signalingServerURL)</span>
                        </div>
                    </div>
                    <button onclick="startConnection()" class="mt-4 w-full bg-blue-600 hover:bg-blue-700 text-white py-2 px-4 rounded font-medium transition shadow-lg shadow-blue-900/20">
                        Reconnect
                    </button>
                </div>

                <!-- Logs Panel -->
                <div class="md:col-span-2 bg-gray-800 rounded-lg p-4 border border-gray-700 flex flex-col h-48">
                    <div class="flex justify-between items-center mb-2">
                        <h3 class="text-sm font-semibold text-gray-400 uppercase tracking-wider">System Logs</h3>
                        <button onclick="clearLogs()" class="text-xs text-gray-500 hover:text-white transition">Clear</button>
                    </div>
                    <div id="logs" class="flex-grow overflow-y-auto scroller font-mono text-xs space-y-1 p-2 bg-gray-900/50 rounded border border-gray-700/50"></div>
                </div>
            </div>
        </main>

        <script>
            // --- Firebase Configuration ---
            const firebaseConfig = {
                apiKey: "AIzaSyC59kWTKog7ziQjlq58-Ak6MybUqsHeFF8",
                authDomain: "webrtc-receiver-36d3e.firebaseapp.com",
                databaseURL: "https://webrtc-receiver-36d3e-default-rtdb.firebaseio.com",
                projectId: "webrtc-receiver-36d3e",
                storageBucket: "webrtc-receiver-36d3e.firebasestorage.app",
                messagingSenderId: "897058750502",
                appId: "1:897058750502:web:e2b6abf64c9cf10c14e6e7",
                measurementId: "G-YK6SQVT9RX"
            };

            // Initialize Firebase
            let firebaseApp = null;
            let analytics = null;
            let db = null;
            let sessionId = Date.now() + '-' + Math.random().toString(36).substr(2, 9);

            try {
                firebaseApp = firebase.initializeApp(firebaseConfig);
                analytics = firebase.analytics();
                db = firebase.firestore();
                console.log('Firebase initialized successfully');
            } catch (error) {
                console.error('Firebase initialization failed:', error);
            }

            // Firebase logger function
            async function logToFirebase(message, level = 'info', metadata = {}) {
                if (!db) return;

                try {
                    await db.collection('webrtc_logs').add({
                        sessionId: sessionId,
                        timestamp: firebase.firestore.FieldValue.serverTimestamp(),
                        clientTimestamp: Date.now(),
                        level: level,
                        message: message,
                        metadata: metadata,
                        userAgent: navigator.userAgent,
                        url: window.location.href
                    });
                } catch (error) {
                    console.error('Failed to log to Firebase:', error);
                }
            }

            // --- Configuration ---
            const CONFIG = {
                signalingUrl: '\(signalingServerURL)',
                iceServers: [
                    { urls: 'stun:stun.l.google.com:19302' },
                    { urls: 'stun:stun1.l.google.com:19302' }
                ]
            };

            // --- State ---
            let pc = null;
            let ws = null;
            const videoElem = document.getElementById('remoteVideo');
            const loader = document.getElementById('loader');
            const loaderText = document.getElementById('loaderText');
            const statusBadge = document.getElementById('connectionStatus');
            const logContainer = document.getElementById('logs');
            const muteBtn = document.getElementById('muteBtn');
            const voiceOnlyIndicator = document.getElementById('voiceOnlyIndicator');

            let hasVideo = false;
            let hasAudio = false;

            // Web Audio API state
            let audioContext = null;
            let audioSource = null;
            let gainNode = null;

            // --- Logger ---
            function log(msg, type = 'info', metadata = {}) {
                const el = document.createElement('div');
                const time = new Date().toLocaleTimeString();
                el.innerHTML = `<span class="text-gray-500">[${time}]</span> <span class="${type === 'error' ? 'text-red-400' : type === 'success' ? 'text-green-400' : 'text-blue-300'}">${msg}</span>`;
                logContainer.appendChild(el);
                logContainer.scrollTop = logContainer.scrollHeight;
                console.log(`[WebRTC] ${msg}`);

                // Also log to Firebase
                logToFirebase(msg, type, metadata);
            }

            function clearLogs() {
                logContainer.innerHTML = '';
            }

            function forceCloseReceiver() {
                try {
                    const context = cast.framework.CastReceiverContext.getInstance();

                    log('Stopping Cast Receiver Context...', 'error');
                    // 1. Tell the framework to stop (terminates the cast session)
                    context.stop();

                    // 2. If the app is still visible after 500ms, force a window close
                    setTimeout(() => {
                        log('Forcing window.close() as fallback...', 'error');
                        window.close();
                    }, 500);
                } catch (error) {
                    log('Cast framework not available, using window.close() directly', 'error');
                    console.error('Cast framework error:', error);
                    // Fallback to regular window close if Cast framework is not available
                    window.close();
                }
            }

            function updateStatus(status) {
                if (status === 'connected') {
                    statusBadge.className = "flex items-center gap-2 px-3 py-1 rounded-full bg-green-900/50 text-green-200 text-sm font-medium border border-green-800 transition-colors";
                    statusBadge.innerHTML = `<div class="w-2 h-2 rounded-full bg-green-500"></div> Connected`;
                    loader.classList.add('opacity-0');
                } else if (status === 'connecting') {
                    statusBadge.className = "flex items-center gap-2 px-3 py-1 rounded-full bg-yellow-900/50 text-yellow-200 text-sm font-medium border border-yellow-800 transition-colors";
                    statusBadge.innerHTML = `<div class="w-2 h-2 rounded-full bg-yellow-500 animate-pulse"></div> Connecting...`;
                    loader.classList.remove('opacity-0');
                    loaderText.innerText = "Negotiating...";
                } else {
                    statusBadge.className = "flex items-center gap-2 px-3 py-1 rounded-full bg-red-900/50 text-red-200 text-sm font-medium border border-red-800 transition-colors";
                    statusBadge.innerHTML = `<div class="w-2 h-2 rounded-full bg-red-500 animate-pulse"></div> Disconnected`;
                    loader.classList.remove('opacity-0');
                    loaderText.innerText = "Waiting for connection...";
                }
            }

            // --- WebRTC Logic ---

            function startConnection() {
                if (ws) ws.close();
                if (pc) pc.close();

                // Cleanup Web Audio API
                if (audioSource) {
                    audioSource.disconnect();
                    audioSource = null;
                }
                if (gainNode) {
                    gainNode.disconnect();
                    gainNode = null;
                }
                if (audioContext && audioContext.state !== 'closed') {
                    audioContext.close();
                    audioContext = null;
                }

                hasVideo = false;
                hasAudio = false;

                log(`Connecting to ${CONFIG.signalingUrl}...`);
                updateStatus('connecting');

                ws = new WebSocket(CONFIG.signalingUrl);
                
                // IMPORTANT: iOS sends binary frames (JSON encoded as Data).
                // We must set binaryType to 'arraybuffer' to handle this cleanly.
                ws.binaryType = 'arraybuffer';

                ws.onopen = async () => {
                    log('WebSocket connected.', 'success');
                    await setupPeerConnection();
                };

                ws.onerror = (err) => {
                    log('WebSocket Error. Check server address.', 'error');
                    updateStatus('disconnected');
                };

                ws.onclose = () => {
                    log('WebSocket Closed.', 'error');
                    updateStatus('disconnected');
                };

                ws.onmessage = async (event) => {
                    try {
                        let messageStr;
                        
                        // Handle Binary Data (iOS Client)
                        if (event.data instanceof ArrayBuffer) {
                            messageStr = new TextDecoder('utf-8').decode(event.data);
                        } else if (event.data instanceof Blob) {
                             // Fallback in case binaryType didn't take
                             messageStr = await event.data.text();
                        } else {
                            // Standard Text Frame
                            messageStr = event.data;
                        }

                        const message = JSON.parse(messageStr);
                        handleSignalingMessage(message);
                    } catch (e) {
                        log('Error parsing signaling message: ' + e.message, 'error');
                        console.error("Original data:", event.data);
                    }
                };
            }

            async function setupPeerConnection() {
                pc = new RTCPeerConnection({ iceServers: CONFIG.iceServers });
                pc.ontrack = (event) => {
                    log(`Track received: ${event.track.kind}`, 'success');

                    if (event.track.kind === 'video') {
                        hasVideo = true;

                        // Get existing stream or create new one with only video
                        const currentStream = videoElem.srcObject;
                        if (!currentStream) {
                            const videoStream = new MediaStream([event.track]);
                            videoElem.srcObject = videoStream;
                            log('Video track attached to video element.', 'success');
                        } else {
                            currentStream.addTrack(event.track);
                            log('Video track added to existing stream.', 'success');
                        }
                    }
                    else if (event.track.kind === 'audio') {
                        hasAudio = true;
                        log('Setting up Web Audio API for audio playback...', 'info');

                        try {
                            // Create AudioContext if not exists
                            if (!audioContext) {
                                const AudioContext = window.AudioContext || window.webkitAudioContext;
                                audioContext = new AudioContext();
                                log(`AudioContext created. State: ${audioContext.state}`, 'info');
                            }

                            // Create MediaStream with only audio track
                            const audioStream = new MediaStream([event.track]);

                            // Create source from stream
                            audioSource = audioContext.createMediaStreamSource(audioStream);

                            // Create gain node for volume control
                            gainNode = audioContext.createGain();
                            gainNode.gain.value = 1.0;

                            // Connect: source → gain → destination (speakers)
                            audioSource.connect(gainNode);
                            gainNode.connect(audioContext.destination);

                            // Resume context if suspended (autoplay restriction)
                            if (audioContext.state === 'suspended') {
                                audioContext.resume().then(() => {
                                    log('AudioContext resumed successfully.', 'success');
                                }).catch(err => {
                                    log(`Failed to resume AudioContext: ${err.message}`, 'error');
                                });
                            }

                            log('Audio track connected via Web Audio API.', 'success');

                            // Track the audio track state
                            event.track.onended = () => {
                                log('Audio track ended.', 'info');
                            };

                        } catch (err) {
                            log(`Web Audio API error: ${err.message}`, 'error');
                            // Fallback: try adding to video element
                            log('Falling back to video element for audio...', 'info');
                            const currentStream = videoElem.srcObject || new MediaStream();
                            currentStream.addTrack(event.track);
                            videoElem.srcObject = currentStream;
                        }
                    }

                    // Update UI after both tracks potentially received
                    setTimeout(() => {
                        const isVoiceOnly = hasAudio && !hasVideo;

                        if (isVoiceOnly) {
                            log('Voice-only stream detected - showing speaker icon', 'info');
                            voiceOnlyIndicator.classList.remove('opacity-0');
                            voiceOnlyIndicator.classList.add('opacity-100');
                        } else {
                            voiceOnlyIndicator.classList.add('opacity-0');
                            voiceOnlyIndicator.classList.remove('opacity-100');
                        }

                        updateStatus('connected');
                    }, 100);
                };

                // Event: ICE Candidate (Local)
                // PROTOCOL MATCH: Wrap in Message(type: "IceCandidate", payload: IceCandidate(...))
                pc.onicecandidate = (event) => {
                    if (event.candidate) {
                        const iceCandidatePayload = {
                            sdp: event.candidate.candidate, // iOS maps this to 'sdp' key
                            sdpMLineIndex: event.candidate.sdpMLineIndex,
                            sdpMid: event.candidate.sdpMid
                        };

                        const message = {
                            type: "IceCandidate", // String(describing: IceCandidate.self)
                            payload: iceCandidatePayload
                        };
                        
                        sendSignal(message);
                        log('Sent local ICE candidate.');
                    }
                };

                pc.onconnectionstatechange = (event) => {
                    const eventTime = performance.now();
                    log(`Peer Connection State: ${pc.connectionState} (at ${eventTime.toFixed(2)}ms)`, 'info', {
                        connectionState: pc.connectionState,
                        performanceTime: eventTime
                    });

                    switch(pc.connectionState) {
                        case "connected":
                            updateStatus('connected');
                            break;
                        case "disconnected":
                        case "failed":
                        case "closed":
                            const disconnectTime = Date.now();
                            log(`[${disconnectTime}] WebRTC Stream stopped. Initiating receiver close...`, 'error', {
                                disconnectTime: disconnectTime,
                                connectionState: pc.connectionState
                            });
                            updateStatus('disconnected');

                            // Close the receiver after a brief delay to show the status update
                            setTimeout(() => {
                                const closeCallTime = Date.now();
                                const delayMs = closeCallTime - disconnectTime;
                                log(`[${closeCallTime}] Calling forceCloseReceiver() - Delay: ${delayMs}ms`, 'error', {
                                    closeCallTime: closeCallTime,
                                    disconnectTime: disconnectTime,
                                    delayMs: delayMs
                                });
                                console.log(`[TIMING] Disconnect event: ${disconnectTime}, forceCloseReceiver() call: ${closeCallTime}, Delay: ${delayMs}ms`);

                                // Log before close attempt
                                const beforeClose = performance.now();
                                forceCloseReceiver();
                                const afterClose = performance.now();

                                // This may not execute if receiver closes immediately
                                const executionTime = (afterClose - beforeClose).toFixed(2);
                                console.log(`[TIMING] forceCloseReceiver() execution time: ${executionTime}ms`);
                                log(`forceCloseReceiver() called - execution took ${executionTime}ms`, 'error', {
                                    executionTime: executionTime,
                                    beforeClose: beforeClose,
                                    afterClose: afterClose
                                });
                            }, 1000);
                            break;
                    }
                };

                pc.addTransceiver('video', { direction: 'recvonly' });
                pc.addTransceiver('audio', { direction: 'recvonly' });

                // Create Offer
                try {
                    const offer = await pc.createOffer();
                    await pc.setLocalDescription(offer);
                    
                    log('Offer created set locally.');

                    // PROTOCOL MATCH: Wrap in Message(type: "SessionDescription", payload: SessionDescription(...))
                    const sessionPayload = {
                        sdp: offer.sdp,
                        type: 'offer' 
                    };

                    const message = {
                        type: "SessionDescription", // String(describing: SessionDescription.self)
                        payload: sessionPayload
                    };

                    sendSignal(message);
                    log('Sent Offer to signaling server.', 'success');
                } catch (e) {
                    log('Error creating offer: ' + e.message, 'error');
                }
            }

            async function handleSignalingMessage(msg) {
                if (!pc) return;

                // Swift Message enum has two cases: sdp, candidate
                // We check the 'type' field which corresponds to the Class name in Swift.

                // Case 1: SessionDescription (Offer/Answer)
                if (msg.type === 'SessionDescription') {
                    const payload = msg.payload;
                    log(`Received SessionDescription (${payload.type})`, 'success');
                    
                    try {
                        await pc.setRemoteDescription(new RTCSessionDescription({
                            type: payload.type,
                            sdp: payload.sdp
                        }));
                        log('Remote description set.');
                    } catch (e) {
                        log('Error setting remote description: ' + e.message, 'error');
                    }
                } 
                // Case 2: IceCandidate
                else if (msg.type === 'IceCandidate') {
                    const payload = msg.payload;
                    log('Received IceCandidate', 'info');
                    
                    try {
                        const candidateInit = {
                            candidate: payload.sdp, // Map back from Swift 'sdp' to JS 'candidate'
                            sdpMLineIndex: payload.sdpMLineIndex,
                            sdpMid: payload.sdpMid
                        };
                        await pc.addIceCandidate(new RTCIceCandidate(candidateInit));
                        log('Added remote ICE candidate.');
                    } catch (e) {
                        log('Error adding ICE candidate: ' + e.message, 'error');
                    }
                }
                else {
                    log('Unknown message type received: ' + msg.type, 'error');
                }
            }

            function sendSignal(data) {
                if (ws && ws.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify(data));
                } else {
                    log('Cannot send signal, WebSocket not open.', 'error');
                }
            }

            function toggleMute() {
                if (gainNode) {
                    // Web Audio API muting via gain control
                    if (gainNode.gain.value > 0) {
                        gainNode.gain.value = 0;
                        muteBtn.innerText = "Unmute";
                        muteBtn.classList.replace('bg-blue-600', 'bg-gray-700');
                        log('Audio muted via Web Audio API', 'info');
                    } else {
                        gainNode.gain.value = 1.0;
                        muteBtn.innerText = "Mute";
                        muteBtn.classList.replace('bg-gray-700', 'bg-blue-600');
                        log('Audio unmuted via Web Audio API', 'info');
                    }
                } else {
                    // Fallback to video element muting
                    if (videoElem.muted) {
                        videoElem.muted = false;
                        muteBtn.innerText = "Mute";
                        muteBtn.classList.replace('bg-gray-700', 'bg-blue-600');
                    } else {
                        videoElem.muted = true;
                        muteBtn.innerText = "Unmute";
                        muteBtn.classList.replace('bg-blue-600', 'bg-gray-700');
                    }
                }
            }

            window.addEventListener('load', () => {
                log('App Loaded. Ready to connect.');
                startConnection();
            });

        </script>
    </body>
    </html>